{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07b594d3-e3d8-4fb4-9d69-129c5e238f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b33b8df5-bf31-45fe-8d49-081182a6dc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b23a072c-4d69-44df-9c22-93a7b72bb731",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"password-data.csv\",on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e16d1a6-630c-43d6-a6a5-9ced0861ea60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>password</th>\n",
       "      <th>strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kzde5577</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kino3434</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>visi7k1yr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>megzy123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lamborghin1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      password  strength\n",
       "0     kzde5577         1\n",
       "1     kino3434         1\n",
       "2    visi7k1yr         1\n",
       "3     megzy123         1\n",
       "4  lamborghin1         1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c742d595-ee2a-40de-bb60-04ac2c83f5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "password    1\n",
       "strength    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e2fd379-e065-43e9-9c8c-7e4a7757b446",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd11fab7-0bd2-49e1-8275-4f2bb6db7f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['strength'] = data['strength'].map({0:'Weak',1:'Medium',2:'Strong'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7b98c78-2265-414f-8bc1-f699be75f93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>password</th>\n",
       "      <th>strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kzde5577</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kino3434</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>visi7k1yr</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>megzy123</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lamborghin1</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      password strength\n",
       "0     kzde5577   Medium\n",
       "1     kino3434   Medium\n",
       "2    visi7k1yr   Medium\n",
       "3     megzy123   Medium\n",
       "4  lamborghin1   Medium"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "991905fc-cd4d-48a8-816c-0bfa1a5333d1",
   "metadata": {},
   "source": [
    "TfidfVectorizer is a feature extraction technique provided by the scikit-learn library in Python. It is commonly used in natural language processing (NLP) to convert a collection of text documents into a matrix of TF-IDF features, which reflect both the frequency of a word in a document and how unique or important that word is across the entire corpus. This makes it particularly useful for tasks where distinguishing important words from common words is critical.\n",
    "\n",
    "What is TF-IDF?\n",
    "TF-IDF stands for Term Frequency-Inverse Document Frequency. It is a statistical measure used to evaluate the importance of a word in a document relative to a collection of documents (corpus).\n",
    "\n",
    "Term Frequency (TF): The number of times a word appears in a document, normalized by the total number of words in that document.\n",
    "Inverse Document Frequency (IDF): A measure of how unique or rare a word is across the entire corpus. It is computed as the logarithm of the total number of documents divided by the number of documents containing the word.\n",
    "The TF-IDF score is the product of the TF and IDF values, giving higher scores to words that are frequent in a document but rare across the corpus.\n",
    "\n",
    "Use Cases of TfidfVectorizer:\n",
    "Text Classification:\n",
    "\n",
    "TfidfVectorizer is often used in text classification tasks, such as spam detection, sentiment analysis, or topic classification. By transforming text data into TF-IDF features, models can focus on words that are more meaningful for distinguishing between classes.\n",
    "Information Retrieval:\n",
    "\n",
    "In search engines or document retrieval systems, TfidfVectorizer is used to rank documents based on their relevance to a search query. Documents with higher TF-IDF scores for the query terms are considered more relevant.\n",
    "Clustering and Topic Modeling:\n",
    "\n",
    "TF-IDF features can be used as input for clustering algorithms like K-Means or topic modeling algorithms like Latent Dirichlet Allocation (LDA). This helps in grouping similar documents together or identifying underlying topics within a corpus.\n",
    "Feature Engineering:\n",
    "\n",
    "TF-IDF vectors can be used as features in various machine learning models, providing a way to incorporate textual information alongside other numerical or categorical features.\n",
    "Document Similarity:\n",
    "\n",
    "TF-IDF is commonly used to measure the similarity between documents. Cosine similarity between TF-IDF vectors can be used to find documents that are similar to a given document, which is useful in recommendation systems or plagiarism detection.\n",
    "Keyword Extraction:\n",
    "\n",
    "TF-IDF scores can help identify keywords in a document by highlighting terms that are unique to that document relative to the corpus. This can be useful for automatic summarization or for identifying key topics in a document.\n",
    "Sentiment Analysis:\n",
    "\n",
    "In sentiment analysis, TF-IDF can be used to identify sentiment-bearing words that are important in determining the sentiment of a document, improving the accuracy of the sentiment classification.\n",
    "Example of TfidfVectorizer in Action:\n",
    "python\n",
    "Copy code\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Example documents\n",
    "documents = [\n",
    "    \"I love programming.\",\n",
    "    \"Programming in Python is fun.\",\n",
    "    \"I love to code in Python.\"\n",
    "]\n",
    "\n",
    "# Initialize TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the documents\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Get the feature names (i.e., the words in the vocabulary)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Convert the sparse matrix to a dense array for better readability\n",
    "X_dense = X.toarray()\n",
    "\n",
    "# Display the results\n",
    "print(\"Vocabulary:\", feature_names)\n",
    "print(\"TF-IDF Matrix:\\n\", X_dense)\n",
    "Explanation:\n",
    "Input Documents:\n",
    "\n",
    "The example consists of three short documents with overlapping vocabulary.\n",
    "TfidfVectorizer Initialization:\n",
    "\n",
    "The TfidfVectorizer is initialized to convert the text data into TF-IDF features.\n",
    "Fit and Transform:\n",
    "\n",
    "The fit_transform method learns the vocabulary from the documents and calculates the TF-IDF scores for each word in each document.\n",
    "Feature Names:\n",
    "\n",
    "The get_feature_names_out method retrieves the vocabulary, showing the words that were transformed into features.\n",
    "TF-IDF Matrix:\n",
    "\n",
    "The output matrix displays the TF-IDF scores for each word in the vocabulary across the documents.\n",
    "Example Output:\n",
    "plaintext\n",
    "Copy code\n",
    "Vocabulary: ['code' 'fun' 'in' 'is' 'love' 'programming' 'python' 'to']\n",
    "TF-IDF Matrix:\n",
    " [[0.         0.         0.         0.         0.861037  0.508542  0.        0.        ]\n",
    "  [0.         0.554228  0.554228  0.554228  0.         0.357455  0.554228  0.        ]\n",
    "  [0.622766  0.         0.476093  0.         0.622766  0.        0.476093  0.622766 ]]\n",
    "Parameters of TfidfVectorizer:\n",
    "max_features: Limits the number of features (words) to the top max_features most important words.\n",
    "ngram_range: Allows you to specify the range of n-values for n-grams (e.g., bigrams, trigrams).\n",
    "stop_words: Allows you to specify a list of words to ignore (e.g., common stopwords).\n",
    "min_df and max_df: Ignore words that appear in fewer than min_df documents or in more than max_df documents, helping to filter out very common or very rare words.\n",
    "use_idf: Whether to use IDF weighting; disabling this effectively turns the vectorizer into a CountVectorizer.\n",
    "Advantages of TfidfVectorizer:\n",
    "Emphasizes Important Words: Unlike CountVectorizer, which just counts word occurrences, TfidfVectorizer emphasizes words that are important in a document but less common across the corpus.\n",
    "Dimensionality Reduction: By down-weighting common words, it helps reduce the impact of very frequent words that are less informative, effectively reducing dimensionality.\n",
    "Better for Document Distinction: It helps in distinguishing documents that share common words but differ in key, distinctive words.\n",
    "Limitations:\n",
    "Interpretability: TF-IDF scores can be less intuitive to interpret than raw counts or word frequencies.\n",
    "Data Sparsity: While TF-IDF helps in down-weighting common terms, it can still result in a very sparse feature matrix, especially for large vocabularies.\n",
    "In summary, TfidfVectorizer is a powerful tool for converting text data into features that reflect both the frequency and importance of words. It is particularly useful in scenarios where distinguishing between important and common words is critical for model performance or data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d296d06-56e7-46bb-87d2-11ce37af09fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\ML-Env\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def word(password):\n",
    "    character=[]\n",
    "    for i in password:\n",
    "        character.append(i)\n",
    "    return character\n",
    "  \n",
    "x = np.array(data[\"password\"])\n",
    "y = np.array(data[\"strength\"])\n",
    "\n",
    "tdif = TfidfVectorizer(tokenizer=word)\n",
    "x = tdif.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dd48d6b-039e-49ba-b250-fc4394612322",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fe37bf1-1aeb-4097-8274-e604042e33a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(xtrain, ytrain)\n",
    "print(model.score(xtest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af38e976-c1f2-4039-8cff-ae8129e95778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "user = getpass.getpass(\"Enter Password: \")\n",
    "data = tdif.transform([user]).toarray()\n",
    "output = model.predict(data)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5dc01432-8173-4274-ba82-c1babd3e2f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "feb751b3-a223-4735-9a15-d0d2521a2e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: <Compressed Sparse Row sparse matrix of dtype 'int64'\n",
      "\twith 15 stored elements and shape (3, 11)>\n",
      "  Coords\tValues\n",
      "  (0, 9)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 4)\t1\n",
      "  (1, 7)\t1\n",
      "  (1, 8)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 1)\t1\n",
      "  (2, 9)\t1\n",
      "  (2, 7)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 2)\t1\n",
      "  (2, 3)\t1\n",
      "  (2, 10)\t1\n",
      "  (2, 5)\t1\n",
      "Vocabulary: ['about' 'ai' 'and' 'are' 'fascinating' 'fields' 'is' 'learning' 'love'\n",
      " 'machine' 'related']\n",
      "Document-Term Matrix:\n",
      " [[0 0 0 0 1 0 1 1 0 1 0]\n",
      " [1 1 0 0 0 0 0 1 1 0 0]\n",
      " [0 1 1 1 0 1 0 1 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Example documents\n",
    "documents = [\n",
    "    \"Machine learning is fascinating.\",\n",
    "    \"I love learning about AI.\",\n",
    "    \"Machine learning and AI are related fields.\"\n",
    "]\n",
    "\n",
    "# Initialize CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the documents\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Get the feature names (i.e., the words in the vocabulary)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Convert the sparse matrix to a dense array for better readability\n",
    "X_dense = X.toarray()\n",
    "\n",
    "# Display the results\n",
    "print(\"X:\",X)\n",
    "print(\"Vocabulary:\", feature_names)\n",
    "print(\"Document-Term Matrix:\\n\", X_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d2bc17-b833-4858-9151-5cd84e396279",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
