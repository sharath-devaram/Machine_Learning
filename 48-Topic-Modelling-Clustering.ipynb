{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOB9F3/KXUICF5o1rWGc1d/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"W1ugV-7mlr53"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem.wordnet import WordNetLemmatizer\n","import string\n","from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n","from sklearn.decomposition import LatentDirichletAllocation\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","nltk.download('omw-1.4')\n","\n","data = pd.read_csv(\"articles.csv\", encoding = 'latin1')\n","print(data.head())"]},{"cell_type":"code","source":["def preprocess_text(text):\n","    # Convert text to lowercase\n","    text = text.lower()\n","    # Remove punctuation\n","    text = text.translate(str.maketrans('', '', string.punctuation))\n","    # Tokenize text\n","    tokens = nltk.word_tokenize(text)\n","    # Remove stopwords\n","    stop_words = set(stopwords.words(\"english\"))\n","    tokens = [word for word in tokens if word not in stop_words]\n","    # Lemmatize tokens\n","    lemma = WordNetLemmatizer()\n","    tokens = [lemma.lemmatize(word) for word in tokens]\n","    # Join tokens to form preprocessed text\n","    preprocessed_text = ' '.join(tokens)\n","    return preprocessed_text\n","\n","data['Article'] = data['Article'].apply(preprocess_text)"],"metadata":{"id":"5BPJjFwxmndx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vectorizer = TfidfVectorizer()\n","x = vectorizer.fit_transform(data['Article'].values)"],"metadata":{"id":"WSLjdTJkmq68"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now we will use an algorithm to identify relationships between the textual data to assign topic labels. We can use the Latent Dirichlet Allocation algorithm for this task. Latent Dirichlet Allocation (LDA) is a generative probabilistic algorithm used to uncover the underlying topics in a corpus of textual data. Letâ€™s use the LDA algorithm to assign topic labels:"],"metadata":{"id":"F22ofT3qmw2K"}},{"cell_type":"code","source":["lda = LatentDirichletAllocation(n_components=5, random_state=42)\n","lda.fit(x)\n","\n","topic_modelling = lda.transform(x)\n","\n","topic_labels = np.argmax(topic_modelling, axis=1)\n","data['topic_labels'] = topic_labels"],"metadata":{"id":"rk9Neervmq4a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.head()"],"metadata":{"id":"TBzcriu4mq2Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ad34_ztamqz2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ap3ej6Hymqxn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"MrerP8WtmqvK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"vFOTgew3mqsq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"23J_BY-Cmqpq"},"execution_count":null,"outputs":[]}]}